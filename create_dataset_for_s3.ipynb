{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcbf56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from os.path import exists, join\n",
    "import json\n",
    "import boto3\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fa2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "\n",
    "    \n",
    "    CLASSES = ['kozijn']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        #self.ids = os.listdir(images_dir)\n",
    "        self.ids = [image_id for image_id in os.listdir(images_dir) if image_id != '.ipynb_checkpoints']\n",
    "        #print(len(self.ids))\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids if image_id != '.ipynb_checkpoints']\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids  if image_id != '.ipynb_checkpoints']\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = np.clip(cv2.imread(self.masks_fps[i], 0),0,1)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "#         masks = [(mask == v) for v in self.class_values]\n",
    "#         mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    \n",
    "    def get_filename(self, i):    #<----Important\n",
    "        return self.images_fps[i], self.masks_fps[i]\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d17d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dir = '/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/images/'\n",
    "y_train_dir = '/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e396af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BaseDataset(x_train_dir, y_train_dir, classes=['kozijn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b886518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03fbb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [781, 200, 100], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68fe26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.indices[:20]\n",
    "valid_dataset = valid_dataset.indices[:20]\n",
    "test_dataset = test_dataset.indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d215fb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/images/5014_43.jpg', '/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/labels/5014_43.jpg')\n"
     ]
    }
   ],
   "source": [
    "for i in test_dataset.indices:\n",
    "    print(dataset.get_filename(i))\n",
    "    break\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc00a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_test_folders(output_dir, version=1):\n",
    "    \"\"\"\n",
    "    Generates folders in output_dir path, \n",
    "    using the S3 database structure for datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    out = Path(output_dir)\n",
    "    path_train = out / \"train\" \n",
    "    path_val = out / \"val\" \n",
    "    path_test = out / \"test\" \n",
    "    os.mkdir(path_train)\n",
    "    os.mkdir(path_val)\n",
    "    os.mkdir(path_test)\n",
    "    \n",
    "    path_train = out / \"train\" / f\"{version}\"\n",
    "    path_val = out / \"val\" / f\"{version}\"\n",
    "    path_test = out / \"test\" / f\"{version}\"\n",
    "    os.mkdir(path_train)\n",
    "    os.mkdir(path_val)\n",
    "    os.mkdir(path_test)\n",
    "    \n",
    "    for p in [path_train, path_test, path_val]:\n",
    "        os.mkdir(p / \"images\")\n",
    "        os.mkdir(p / \"segmentations\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f573a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_and_masks_into_folders(dataset_dir, dataset, train_indexes, val_indexes, test_indexes, version=1):\n",
    "    \n",
    "    for index in train_indexes:\n",
    "        image_path, mask_path = dataset.get_filename(index)\n",
    "        image_new_path = Path(dataset_dir) / \"train\" / f\"{version}\" / \"images\" / image_path.split(\"/\")[-1]\n",
    "        mask_new_path = Path(dataset_dir) / \"train\" / f\"{version}\" / \"segmentations\" / mask_path.split(\"/\")[-1]\n",
    "        shutil.move(image_path, image_new_path)\n",
    "        shutil.move(mask_path, mask_new_path)\n",
    "    \n",
    "    for index in val_indexes:\n",
    "        image_path, mask_path = dataset.get_filename(index)\n",
    "        image_new_path = Path(dataset_dir) / \"val\" / f\"{version}\" / \"images\" / image_path.split(\"/\")[-1]\n",
    "        mask_new_path = Path(dataset_dir) / \"val\" / f\"{version}\" / \"segmentations\" / mask_path.split(\"/\")[-1]\n",
    "        shutil.move(image_path, image_new_path)\n",
    "        shutil.move(mask_path, mask_new_path)\n",
    "        \n",
    "    for index in test_indexes:\n",
    "        image_path, mask_path = dataset.get_filename(index)\n",
    "        image_new_path = Path(dataset_dir) / \"test\" / f\"{version}\" / \"images\" / image_path.split(\"/\")[-1]\n",
    "        mask_new_path = Path(dataset_dir) / \"test\" / f\"{version}\" / \"segmentations\" / mask_path.split(\"/\")[-1]\n",
    "        shutil.move(image_path, image_new_path)\n",
    "        shutil.move(mask_path, mask_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94682b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonlines(samples_list, output_dir: str):\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    images_dir = output_dir / \"images\"\n",
    "    segmentations_dir = output_dir / \"segmentations\"\n",
    "\n",
    "    with open(join(output_dir, \"dataset.jsonlines\"), \"w\") as file:\n",
    "        for img, segment in samples_list.items():\n",
    "            if exists(images_dir / img) and exists(\n",
    "                segmentations_dir / segment\n",
    "            ):\n",
    "                sample = {\"image\": img, \"segmentation\": segment}\n",
    "\n",
    "                file.write(json.dumps(sample))\n",
    "                file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aad73ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metajson_with_classmap(class_map: dict, detection_type: str, output_dir: str):\n",
    "\n",
    "\n",
    "    meta_json = {}\n",
    "    meta_json[\"classmap\"] = class_map\n",
    "    meta_json[\"detection_type\"] = detection_type\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    with open(output_dir / \"meta.json\", \"w\") as file:\n",
    "        file.write(json.dumps(meta_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ea4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_list(dataset, indexes):\n",
    "    samples_list = {}\n",
    "    for index in indexes:\n",
    "        image_path, mask_path = dataset.get_filename(index)\n",
    "        samples_list[image_path.split(\"/\")[-1]] = mask_path.split(\"/\")[-1]\n",
    "    return samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56377051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonlines_train_val_test(output_dir, dataset, train_indices, val_indices, test_indices, version=1):\n",
    "    \n",
    "    train_samples_list = create_samples_list(dataset, train_indices)\n",
    "    create_jsonlines(train_samples_list, Path(output_dir) / \"train\" / f\"{version}\")\n",
    "    \n",
    "    val_samples_list = create_samples_list(dataset, val_indices)\n",
    "    create_jsonlines(val_samples_list, Path(output_dir) / \"val\" / f\"{version}\")\n",
    "    \n",
    "    test_samples_list = create_samples_list(dataset, test_indices)\n",
    "    create_jsonlines(test_samples_list, Path(output_dir) / \"test\" / f\"{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734c0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metajson_train_val_test(class_map: dict, detection_type: str, output_dir: str, version = 1):\n",
    "    for d in [\"train\", \"val\", \"test\"]:\n",
    "        create_metajson_with_classmap(class_map, detection_type, Path(output_dir) / d / f\"{version}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1f128d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_from_local_to_s3(root_dir_path, bucket, version=1):\n",
    "    root_dir_name = os.path.basename(root_dir_path)\n",
    "\n",
    "    client = boto3.client('s3')\n",
    "    \n",
    "    for d in ['train', 'val', 'test']:\n",
    "        meta_file = Path(root_dir_path) / d / f\"{version}\" / \"meta.json\"\n",
    "        meta_object = Path(root_dir_name) / d / f\"{version}\" / \"meta.json\"\n",
    "        print(str(meta_file))\n",
    "        print(str(meta_object))\n",
    "        client.upload_file(str(meta_file), bucket, str(meta_object))\n",
    "\n",
    "        jsonlines_file = Path(root_dir_path) / d / f\"{version}\" / \"dataset.jsonlines\"\n",
    "        jsonlines_object = Path(root_dir_name) / d / f\"{version}\" / \"dataset.jsonlines\"\n",
    "        client.upload_file(str(jsonlines_file), bucket, str(jsonlines_object))\n",
    "\n",
    "        images = (Path(root_dir_path) / d / f\"{version}\" / \"images\" / o for o in os.listdir(Path(root_dir_path) / d / f\"{version}\" / \"images\") if '.ipynb' not in o)\n",
    "        \n",
    "        upload_todo_images = []\n",
    "        for image_file in images:\n",
    "            upload_todo_images.append((str(image_file), bucket, str(Path(root_dir_name) / d / f\"{version}\" / \"images\" / os.path.basename(image_file))))\n",
    "        \n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            completed = 0\n",
    "\n",
    "            futures = []\n",
    "            for upload_todo in upload_todo_images:\n",
    "                futures.append(\n",
    "                    executor.submit(client.upload_file, *upload_todo)\n",
    "                )\n",
    "\n",
    "            for i, done in enumerate(as_completed(futures)):\n",
    "                done.result()\n",
    "\n",
    "                if (i + 1) % 20 == 0:\n",
    "                    completed += 20\n",
    "                    print(\n",
    "                        f\"uploaded {completed}/{len(upload_todo_images)} images\"\n",
    "                    )\n",
    "#         for image_file in images:\n",
    "#             client.upload_file(str(image_file), bucket, str(Path(root_dir_name) / d / f\"{version}\" / \"images\" / os.path.basename(image_file)))\n",
    "\n",
    "#         segmentations = (Path(root_dir_path) / d / f\"{version}\" / \"segmentations\" / o for o in os.listdir(Path(root_dir_path) / d / f\"{version}\" / \"segmentations\") if '.ipynb' not in o)\n",
    "\n",
    "#         for segm_file in segmentations:\n",
    "#             client.upload_file(str(segm_file), bucket, str(Path(root_dir_name) / d / f\"{version}\" / \"segmentations\" / os.path.basename(segm_file)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dff383b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#         completed = 0\n",
    "\n",
    "#         futures = []\n",
    "#         for download_todo in download_list:\n",
    "#             futures.append(\n",
    "#                 executor.submit(client.download_file, *download_todo)\n",
    "#             )\n",
    "\n",
    "#         for i, done in enumerate(as_completed(futures)):\n",
    "#             done.result()\n",
    "\n",
    "#             if (i + 1) % 50 == 0:\n",
    "#                 completed += 50\n",
    "#                 logger.info(\n",
    "#                     f\"downloaded {completed}/{len(download_list)} imgs & labls\"\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21eef8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_path = '/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations'\n",
    "version =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca52c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations/train/1/meta.json\n",
      "kozijns-segmentations/train/1/meta.json\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f519183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e317af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = os.path.basename(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d420b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_train_val_test_dirs('/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4649d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_images_and_masks_into_folders('/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations', dataset, train_dataset, valid_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c017db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_jsonlines_train_val_test('/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations', dataset, train_dataset, valid_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e841b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "classmap = {\"background\": 0, \"kozijn\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad758b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metajson_train_val_test(classmap, 'segmentation', '/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cd7beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations/train/1/meta.json\n",
      "kozijns-segmentations/train/1/meta.json\n",
      "uploaded 20/20 images\n",
      "/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations/val/1/meta.json\n",
      "kozijns-segmentations/val/1/meta.json\n",
      "uploaded 20/20 images\n",
      "/Users/zed/viscode-github/window-frame-types/notebooks/dataset_for_ml/kozijns-segmentations/test/1/meta.json\n",
      "kozijns-segmentations/test/1/meta.json\n",
      "uploaded 20/20 images\n"
     ]
    }
   ],
   "source": [
    "upload_from_local_to_s3(root_dir_path, \"spotr-datasets\" ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c183ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653febc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51a2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
